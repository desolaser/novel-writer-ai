type CompletionTokensDetails = {
    reasoning_tokens?: number; // Tokens generated by the model for reasoning (optional)
};

type Usage = {
    completion_tokens: number; // Number of tokens in the generated completion
    prompt_tokens: number; // Number of tokens in the prompt
    prompt_cache_hit_tokens: number; // Number of tokens in the prompt that hits the context cache
    prompt_cache_miss_tokens: number; // Number of tokens in the prompt that misses the context cache
    total_tokens: number; // Total number of tokens used in the request (prompt + completion)
    completion_tokens_details?: CompletionTokensDetails; // Breakdown of tokens used in a completion (optional)
};

type CompletionResponse = {
    stream?: any; // AsyncIterable for streaming responses
    text?: string;
    usage?: Usage;
    model: string;
};

export type {
    CompletionResponse
};
